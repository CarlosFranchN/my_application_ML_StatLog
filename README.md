# üè¶ An√°lise de Risco de Cr√©dito (Credit Scoring) - German Credit Data

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Status](https://img.shields.io/badge/Status-Conclu√≠do-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

## üìÑ Descri√ß√£o do Projeto

Este projeto consiste no desenvolvimento de um modelo de Machine Learning para prever o risco de inadimpl√™ncia (default) de clientes banc√°rios. O objetivo n√£o √© apenas classificar corretamente, mas **maximizar o lucro da institui√ß√£o financeira** atrav√©s de uma **Matriz de Custos** personalizada e garantir a transpar√™ncia das decis√µes via **SHAP (Explainable AI)**.

O dataset utilizado foi o cl√°ssico **Statlog (German Credit Data)**, que cont√©m dados demogr√°ficos e hist√≥rico financeiro de 1.000 clientes.

---

## üíº O Problema de Neg√≥cio

No cen√°rio de cr√©dito, os erros do modelo t√™m pesos financeiros diferentes:
* **Erro Tipo I (Falso Positivo):** Negar cr√©dito a um bom pagador. O banco perde os juros (Custo de Oportunidade).
* **Erro Tipo II (Falso Negativo):** Dar cr√©dito a um mau pagador. O banco perde o valor principal emprestado (Preju√≠zo Real).

**Premissa adotada neste projeto:** O preju√≠zo de um calote √© **5x maior** que o lucro perdido de um bom cliente. O modelo foi otimizado para respeitar essa regra de neg√≥cio.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python
* **Manipula√ß√£o de Dados:** Pandas, Numpy
* **Visualiza√ß√£o:** Matplotlib, Seaborn
* **Machine Learning:** Scikit-Learn (Random Forest / XGBoost - *ajuste conforme seu modelo*)
* **Explainability:** SHAP (SHapley Additive exPlanations)
* **Balanceamento:** SMOTE (Synthetic Minority Over-sampling Technique)

---

## üìä Pipeline do Projeto

1.  **An√°lise Explorat√≥ria (EDA):** Identifica√ß√£o de padr√µes em vari√°veis como `Duration of Credit`, `Credit Amount` e `Checking Account Status`.
2.  **Pr√©-processamento:**
    * Codifica√ß√£o de vari√°veis categ√≥ricas (OneHotEncoding/LabelEncoder).
    * Tratamento de dados desbalanceados (70% bons / 30% ruins).
3.  **Modelagem:** Treinamento de algoritmos focados em otimiza√ß√£o de *Recall* (para capturar os maus pagadores).
4.  **Avalia√ß√£o Financeira:** Aplica√ß√£o da Matriz de Custos para calcular o lucro estimado do modelo versus um cen√°rio sem modelo.
5.  **Explicabilidade:** Uso do SHAP para entender quais features impactam a decis√£o de cr√©dito.

---

## üìà Principais Resultados

### 1. Performance dos Modelos

## üìä Comparativo de Modelos

Como o objetivo do neg√≥cio √© evitar o calote, a m√©trica mais importante para n√≥s √© o **Recall da Classe 2 (Maus Pagadores)**. Um modelo com alta acur√°cia que n√£o detecta os caloteiros n√£o serve para o banco.

| Modelo | Acur√°cia Global | Recall (Maus Pagadores) | F1-Score (Maus Pagadores) | Observa√ß√£o |
| :--- | :---: | :---: | :---: | :--- |
| **Logistic Regression** | 66% | **0.60** üèÜ | 0.50 | Melhor detector de risco |
| **Random Forest** | 73% | 0.51 | **0.52** | Melhor equil√≠brio geral |
| Support Vector Machine | **75%** | 0.38 | 0.47 | Alta acur√°cia, mas deixa passar muitos riscos |
| Decision Tree | 67% | 0.32 | 0.35 | Baixa performance em risco |
| K-Nearest Neighbors | 70% | 0.05 ‚ùå | 0.08 | Incapaz de detectar caloteiros |

> **Conclus√£o:** Apesar do SVM ter a maior acur√°cia (75%), a **Regress√£o Log√≠stica** se mostrou mais vi√°vel para o neg√≥cio por identificar 60% dos maus pagadores, contra apenas 38% do SVM.


### 2. Impacto Financeiro (Matriz de Custos)
Para demonstrar a aplicabilidade pr√°tica dos modelos, simulamos uma opera√ß√£o de cr√©dito real. Em problemas de risco, a m√©trica t√©cnica (Acur√°cia) √© menos importante do que o **Lucro L√≠quido**.

#### 1. Premissas da Simula√ß√£o
Adotamos os seguintes valores para cada cliente da base de teste:
* **Empr√©stimo M√©dio:** R$ 5.000,00
* **Lucro (Juros Recebidos):** R$ 2.000,00 (Para bons pagadores aprovados)
* **Preju√≠zo (Inadimpl√™ncia):** -R$ 5.000,00 (Para maus pagadores aprovados)

#### 2. Resultados da Simula√ß√£o

Comparativo do Lucro L√≠quido gerado por cada modelo versus um cen√°rio base (sem modelo de IA).

| Modelo | Resultado Financeiro | Lucro Extra vs. Sem Modelo | Performance |
| :--- | :--- | :--- | :---: |
| **Logistic Regression** | **R$ 121.000,00** | **+ R$ 112.000,00** | üèÜ **Campe√£o** |
| Random Forest | R$ 118.000,00 | + R$ 109.000,00 | ü•à Vice |
| Decision Tree | R$ 112.000,00 | + R$ 103.000,00 | ü•â 3¬∫ Lugar |
| *Sem Modelo (Baseline)* | *R$ 9.000,00* | *R$ 0,00* | ‚ö†Ô∏è Risco Alto |
| K-Nearest Neighbors | R$ 1.000,00 | <span style="color:red">- R$ 8.000,00</span> | ‚ùå Preju√≠zo |


#### 3. Conclus√£o de Neg√≥cio

* **A Melhor Escolha:** A **Regress√£o Log√≠stica** foi o modelo mais eficiente. Apesar de ter uma acur√°cia global menor que o SVM ou Random Forest, ela teve o melhor desempenho na detec√ß√£o de caloteiros (Recall da Classe 2), maximizando o lucro final.
* **O Perigo do KNN:** O modelo KNN apresentou um desempenho financeiro **pior do que n√£o ter modelo nenhum** (R$ 1.000 vs R$ 9.000 do baseline). Isso ocorre porque ele falhou em identificar os perfis de risco, aprovando empr√©stimos que resultaram em preju√≠zo massivo.


### 4. Diagn√≥stico Inicial: O Risco do Limiar Padr√£o (0.5)

Inicialmente, rodamos a simula√ß√£o financeira utilizando o **threshold padr√£o de 50%** (ou seja, s√≥ negamos cr√©dito se a certeza de calote for > 0.5).

**O resultado foi desastroso:** Como o custo do calote √© muito alto (5x o lucro), ser "leniente" gerou preju√≠zo em **todos os modelos**. Isso prova que usar Machine Learning "fora da caixa" sem alinhamento com o neg√≥cio √© perigoso.

<details>
  <summary>üîª Clique para expandir os Logs de Simula√ß√£o (Cen√°rio de Preju√≠zo)</summary>

```text
--- Simula√ß√£o Financeira (Decision Tree) ---
Clientes Bons Aprovados: 126 (Lucro: R$ 126.000)
Calotes Tomados: 28 (Preju√≠zo: R$ -140.000)
RESULTADO L√çQUIDO: R$ -55.000,00 (PREJU√çZO)

--- Simula√ß√£o Financeira (Random Forest) ---
Clientes Bons Aprovados: 139 (Lucro: R$ 139.000)
Calotes Tomados: 32 (Preju√≠zo: R$ -160.000)
RESULTADO L√çQUIDO: R$ -49.000,00 (PREJU√çZO)

--- Simula√ß√£o Financeira (Logistic Regression) ---
Clientes Bons Aprovados: 118 (Lucro: R$ 118.000)
Calotes Tomados: 23 (Preju√≠zo: R$ -115.000)
RESULTADO L√çQUIDO: R$ -46.000,00 (PREJU√çZO)

--- Simula√ß√£o Financeira (K-Nearest Neighbors) ---
Clientes Bons Aprovados: 83 (Lucro: R$ 83.000)
Calotes Tomados: 33 (Preju√≠zo: R$ -165.000)
RESULTADO L√çQUIDO: R$ -166.000,00 (PREJU√çZO CR√çTICO)
```
</details>

#### 5. A Solu√ß√£o: Otimiza√ß√£o do Limiar (Threshold Tuning)

Visto que o padr√£o gerou preju√≠zo, realizamos uma an√°lise de sensibilidade variando a r√©gua de corte. O objetivo foi encontrar o "Sweet Spot": o ponto exato onde maximizamos o lucro barrando os caloteiros, sem negar cr√©dito excessivo aos bons pagadores.

Realizamos uma an√°lise de sensibilidade variando o limiar de decis√£o de 0 a 100% para encontrar o ponto de lucro m√°ximo ("Sweet Spot").

![Gr√°fico de Lucratividade por Threshold](img/analise_lucratividade.png)


**Insights do Gr√°fico:**
1.  **A Virada do Jogo:** Ao ajustarmos o limiar da Regress√£o Log√≠stica de 0.50 para ~0.22, transformamos um preju√≠zo de R$ 46.000 em um **Lucro de R$ 121.000**.
2. **Rigor Necess√°rio:** O gr√°fico mostra que, para este neg√≥cio, precisamos ser conservadores. Devemos negar cr√©dito para qualquer cliente com probabilidade de risco acima de 20% a 25%.   
3.  **Robustez:** Robustez: A Regress√£o Log√≠stica (linha laranja) provou ser o modelo mais est√°vel financeiramente, mantendo-se na zona de lucro por uma faixa maior de limiares do que o Random Forest.

---

## üöÄ Como Executar o Projeto

1. Clone o reposit√≥rio:
```bash
git clone [https://github.com/SEU_USUARIO/NOME_DO_REPO.git](https://github.com/SEU_USUARIO/NOME_DO_REPO.git)
```

2. Instale as depend√™ncias:
```bash
    pip install -r requirements.txt
```


## Autor
[Carlos Franch Arag√£o]
