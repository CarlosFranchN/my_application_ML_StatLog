# üè¶ An√°lise de Risco de Cr√©dito (Credit Scoring) - German Credit Data

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Status](https://img.shields.io/badge/Status-Conclu√≠do-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

## üìÑ Descri√ß√£o do Projeto

Este projeto consiste no desenvolvimento de um modelo de Machine Learning para prever o risco de inadimpl√™ncia (default) de clientes banc√°rios. O objetivo n√£o √© apenas classificar corretamente, mas **maximizar o lucro da institui√ß√£o financeira** atrav√©s de uma **Matriz de Custos** personalizada e garantir a transpar√™ncia das decis√µes via **SHAP (Explainable AI)**.

O dataset utilizado foi o cl√°ssico **Statlog (German Credit Data)**, que cont√©m dados demogr√°ficos e hist√≥rico financeiro de 1.000 clientes.

---

## üíº O Problema de Neg√≥cio

No cen√°rio de cr√©dito, os erros do modelo t√™m pesos financeiros diferentes:
* **Erro Tipo I (Falso Positivo):** Negar cr√©dito a um bom pagador. O banco perde os juros (Custo de Oportunidade).
* **Erro Tipo II (Falso Negativo):** Dar cr√©dito a um mau pagador. O banco perde o valor principal emprestado (Preju√≠zo Real).

**Premissa adotada neste projeto:** O preju√≠zo de um calote √© **5x maior** que o lucro perdido de um bom cliente. O modelo foi otimizado para respeitar essa regra de neg√≥cio.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python
* **Manipula√ß√£o de Dados:** Pandas, Numpy
* **Visualiza√ß√£o:** Matplotlib, Seaborn
* **Machine Learning:** Scikit-Learn (Random Forest / XGBoost - *ajuste conforme seu modelo*)
* **Explainability:** SHAP (SHapley Additive exPlanations)
* **Balanceamento:** SMOTE (Synthetic Minority Over-sampling Technique)

---

## üìä Pipeline do Projeto

1.  **An√°lise Explorat√≥ria (EDA):** Identifica√ß√£o de padr√µes em vari√°veis como `Duration of Credit`, `Credit Amount` e `Checking Account Status`.
2.  **Pr√©-processamento:**
    * Codifica√ß√£o de vari√°veis categ√≥ricas (OneHotEncoding/LabelEncoder).
    * Tratamento de dados desbalanceados (70% bons / 30% ruins).
3.  **Modelagem:** Treinamento de algoritmos focados em otimiza√ß√£o de *Recall* (para capturar os maus pagadores).
4.  **Avalia√ß√£o Financeira:** Aplica√ß√£o da Matriz de Custos para calcular o lucro estimado do modelo versus um cen√°rio sem modelo.
5.  **Explicabilidade:** Uso do SHAP para entender quais features impactam a decis√£o de cr√©dito.

---

## üìà Principais Resultados

### 1. Performance dos Modelos

## üìä Comparativo de Modelos

Como o objetivo do neg√≥cio √© evitar o calote, a m√©trica mais importante para n√≥s √© o **Recall da Classe 2 (Maus Pagadores)**. Um modelo com alta acur√°cia que n√£o detecta os caloteiros n√£o serve para o banco.

| Modelo | Acur√°cia Global | Recall (Maus Pagadores) | F1-Score (Maus Pagadores) | Observa√ß√£o |
| :--- | :---: | :---: | :---: | :--- |
| **Logistic Regression** | 66% | **0.60** üèÜ | 0.50 | Melhor detector de risco |
| **Random Forest** | 73% | 0.51 | **0.52** | Melhor equil√≠brio geral |
| Support Vector Machine | **75%** | 0.38 | 0.47 | Alta acur√°cia, mas deixa passar muitos riscos |
| Decision Tree | 67% | 0.32 | 0.35 | Baixa performance em risco |
| K-Nearest Neighbors | 70% | 0.05 ‚ùå | 0.08 | Incapaz de detectar caloteiros |

> **Conclus√£o:** Apesar do SVM ter a maior acur√°cia (75%), a **Regress√£o Log√≠stica** se mostrou mais vi√°vel para o neg√≥cio por identificar 60% dos maus pagadores, contra apenas 38% do SVM.


### 2. Impacto Financeiro (Matriz de Custos)
Para demonstrar a aplicabilidade pr√°tica dos modelos, simulamos uma opera√ß√£o de cr√©dito real. Em problemas de risco, a m√©trica t√©cnica (Acur√°cia) √© menos importante do que o **Lucro L√≠quido**.

#### 1. Premissas da Simula√ß√£o
Adotamos os seguintes valores para cada cliente da base de teste:
* **Empr√©stimo M√©dio:** R$ 5.000,00
* **Lucro (Juros Recebidos):** R$ 2.000,00 (Para bons pagadores aprovados)
* **Preju√≠zo (Inadimpl√™ncia):** -R$ 5.000,00 (Para maus pagadores aprovados)

#### 2. Resultados da Simula√ß√£o

Comparativo do Lucro L√≠quido gerado por cada modelo versus um cen√°rio base (sem modelo de IA).

| Modelo | Resultado Financeiro | Lucro Extra vs. Sem Modelo | Performance |
| :--- | :--- | :--- | :---: |
| **Logistic Regression** | **R$ 121.000,00** | **+ R$ 112.000,00** | üèÜ **Campe√£o** |
| Random Forest | R$ 118.000,00 | + R$ 109.000,00 | ü•à Vice |
| Decision Tree | R$ 112.000,00 | + R$ 103.000,00 | ü•â 3¬∫ Lugar |
| *Sem Modelo (Baseline)* | *R$ 9.000,00* | *R$ 0,00* | ‚ö†Ô∏è Risco Alto |
| K-Nearest Neighbors | R$ 1.000,00 | <span style="color:red">- R$ 8.000,00</span> | ‚ùå Preju√≠zo |


#### 3. Conclus√£o de Neg√≥cio

* **A Melhor Escolha:** A **Regress√£o Log√≠stica** foi o modelo mais eficiente. Apesar de ter uma acur√°cia global menor que o SVM ou Random Forest, ela teve o melhor desempenho na detec√ß√£o de caloteiros (Recall da Classe 2), maximizando o lucro final.
* **O Perigo do KNN:** O modelo KNN apresentou um desempenho financeiro **pior do que n√£o ter modelo nenhum** (R$ 1.000 vs R$ 9.000 do baseline). Isso ocorre porque ele falhou em identificar os perfis de risco, aprovando empr√©stimos que resultaram em preju√≠zo massivo.


#### 4. Simula√ß√£o Financeira
```
--- Simula√ß√£o Financeira (Decision Tree) ---
Clientes Bons Aprovados: 126 (Lucro: R$ 126000)
Clientes Bons Rejeitados (Custo de Oportunidade): 41 (Perda: R$ 41000)
Calotes Tomados: 28 (Preju√≠zo: R$ -140000)
=============================================
RESULTADO L√çQUIDO DA CARTEIRA: R$ -55,000.00



--- Simula√ß√£o Financeira (Random Forest) ---
Clientes Bons Aprovados: 139 (Lucro: R$ 139000)
Clientes Bons Rejeitados (Custo de Oportunidade): 28 (Perda: R$ 28000)
Calotes Tomados: 32 (Preju√≠zo: R$ -160000)
=============================================
RESULTADO L√çQUIDO DA CARTEIRA: R$ -49,000.00



--- Simula√ß√£o Financeira (Logistic Regression) ---
Clientes Bons Aprovados: 118 (Lucro: R$ 118000)
Clientes Bons Rejeitados (Custo de Oportunidade): 49 (Perda: R$ 49000)
Calotes Tomados: 23 (Preju√≠zo: R$ -115000)
=============================================
RESULTADO L√çQUIDO DA CARTEIRA: R$ -46,000.00



--- Simula√ß√£o Financeira (K-Nearest Neighbors) ---
Clientes Bons Aprovados: 83 (Lucro: R$ 83000)
Clientes Bons Rejeitados (Custo de Oportunidade): 84 (Perda: R$ 84000)
Calotes Tomados: 33 (Preju√≠zo: R$ -165000)
=============================================
RESULTADO L√çQUIDO DA CARTEIRA: R$ -166,000.00

```

#### 5. Otimiza√ß√£o do Limiar de Decis√£o (Threshold Tuning)Otimiza√ß√£o do Limiar de Decis√£o (Threshold Tuning)

Por padr√£o, algoritmos de Machine Learning classificam um cliente como "Mau Pagador" se a probabilidade for maior que 50% (0.5). Por√©m, em nossa an√°lise financeira, descobrimos que **esse padr√£o gera preju√≠zo**.

Realizamos uma an√°lise de sensibilidade variando o limiar de decis√£o de 0 a 100% para encontrar o ponto de lucro m√°ximo ("Sweet Spot").

![Gr√°fico de Lucratividade por Threshold](img/analise_lucratividade.png)


**Insights do Gr√°fico:**
1.  **O Perigo do Padr√£o (0.5):** Se utiliz√°ssemos o threshold padr√£o de 0.5, a carteira entraria em preju√≠zo (regi√£o abaixo da linha vermelha tracejada), pois o modelo seria "leniente" demais.
2.  **O Ponto √ìtimo:** O lucro m√°ximo √© atingido com um threshold mais rigoroso, entre **0.15 e 0.25**. Isso significa que devemos negar cr√©dito para qualquer cliente com probabilidade de calote acima de ~20%, e n√£o esperar chegar a 50%.
3.  **Robustez:** A Regress√£o Log√≠stica (Linha Laranja) se mostrou mais est√°vel, mantendo a lucratividade positiva por uma faixa maior de limiares do que o Random Forest.

---

## üöÄ Como Executar o Projeto

1. Clone o reposit√≥rio:
```bash
git clone [https://github.com/SEU_USUARIO/NOME_DO_REPO.git](https://github.com/SEU_USUARIO/NOME_DO_REPO.git)
```

2. Instale as depend√™ncias:
```bash
    pip install -r requirements.txt
```


## Autor
[Carlos Franch Arag√£o]



### O que voc√™ precisa fazer agora:

1.  **Preencher os "XX%"** na se√ß√£o de Resultados com os n√∫meros reais do seu notebook.
2.  **Salvar as imagens:** Salve o gr√°fico do SHAP (`summary_plot`) e a Matriz de Confus√£o como imagens (png) numa pasta e coloque no README (posso te ensinar a linkar a imagem se precisar).
3.  **Requirements:** Lembre-se de gerar o `requirements.txt` (`pip freeze > requirements.txt`).

Ficou do jeito que voc√™ queria? Se quiser ajustar o tom para ser mais "t√©cnico" ou mais "executivo", me avise!